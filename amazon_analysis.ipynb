{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43739 entries, 0 to 43738\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order_ID         43739 non-null  object \n",
      " 1   Agent_Age        43739 non-null  int64  \n",
      " 2   Agent_Rating     43685 non-null  float64\n",
      " 3   Store_Latitude   43739 non-null  float64\n",
      " 4   Store_Longitude  43739 non-null  float64\n",
      " 5   Drop_Latitude    43739 non-null  float64\n",
      " 6   Drop_Longitude   43739 non-null  float64\n",
      " 7   Order_Date       43739 non-null  object \n",
      " 8   Order_Time       43739 non-null  object \n",
      " 9   Pickup_Time      43739 non-null  object \n",
      " 10  Weather          43648 non-null  object \n",
      " 11  Traffic          43739 non-null  object \n",
      " 12  Vehicle          43739 non-null  object \n",
      " 13  Area             43739 non-null  object \n",
      " 14  Delivery_Time    43739 non-null  int64  \n",
      " 15  Category         43739 non-null  object \n",
      "dtypes: float64(5), int64(2), object(9)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "amazon_del = pd.read_csv(\"amazon_delivery.csv\")\n",
    "amazon_del.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quick look column by column**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Order_ID**  \n",
    "Should be equivalent to PRIMARY KEY of a SQL table, only unique values. If so it can be removed when building a machine learning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates_order = amazon_del.duplicated(subset=[\"Order_ID\"])\n",
    "print(len(amazon_del[duplicates_order]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All IDs are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agent_Age**  \n",
    "On first sight everything seems ok. Type: integer and no missing values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43739.000000\n",
       "mean        29.567137\n",
       "std          5.815155\n",
       "min         15.000000\n",
       "25%         25.000000\n",
       "50%         30.000000\n",
       "75%         35.000000\n",
       "max         50.000000\n",
       "Name: Agent_Age, dtype: float64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Agent_Age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Age = 0 or other abeerrant numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agent Rating**  \n",
    "Based on the info() table there are apparent missing values (54)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012345961270262237"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ratings = amazon_del[amazon_del[\"Agent_Rating\"].isna()]\n",
    "non_missing_ratings = amazon_del[~(amazon_del[\"Agent_Rating\"].isna())]\n",
    "len(missing_ratings)/len(amazon_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could potentially remove the values as they represent less than 1%. But I will see if other values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traffic\n",
       "Low        23\n",
       "Jam        15\n",
       "Medium     14\n",
       "High        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ratings[\"Traffic\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weather\n",
       "Windy         12\n",
       "Sunny         11\n",
       "Cloudy        11\n",
       "Stormy         8\n",
       "Sandstorms     7\n",
       "Fog            5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ratings[\"Weather\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can remove them. There are no obvious reason of these missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 43685 entries, 0 to 43738\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order_ID         43685 non-null  object \n",
      " 1   Agent_Age        43685 non-null  int64  \n",
      " 2   Agent_Rating     43685 non-null  float64\n",
      " 3   Store_Latitude   43685 non-null  float64\n",
      " 4   Store_Longitude  43685 non-null  float64\n",
      " 5   Drop_Latitude    43685 non-null  float64\n",
      " 6   Drop_Longitude   43685 non-null  float64\n",
      " 7   Order_Date       43685 non-null  object \n",
      " 8   Order_Time       43685 non-null  object \n",
      " 9   Pickup_Time      43685 non-null  object \n",
      " 10  Weather          43594 non-null  object \n",
      " 11  Traffic          43685 non-null  object \n",
      " 12  Vehicle          43685 non-null  object \n",
      " 13  Area             43685 non-null  object \n",
      " 14  Delivery_Time    43685 non-null  int64  \n",
      " 15  Category         43685 non-null  object \n",
      "dtypes: float64(5), int64(2), object(9)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "amazon_del = amazon_del.drop(missing_ratings.index, axis=0)\n",
    "amazon_del.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Store Latitude**  \n",
    "When the latitude is positive we are above the equator line. When the latitude is negative we are south to the equator line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43685.000000\n",
       "mean        17.214543\n",
       "std          7.750885\n",
       "min        -30.902872\n",
       "25%         12.933298\n",
       "50%         18.551440\n",
       "75%         22.732225\n",
       "max         30.914057\n",
       "Name: Store_Latitude, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Store_Latitude\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Store Longitude**  \n",
    "No apparent missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43685.000000\n",
       "mean        70.668593\n",
       "std         21.459258\n",
       "min        -88.366217\n",
       "25%         73.170283\n",
       "50%         75.898497\n",
       "75%         78.045359\n",
       "max         88.433452\n",
       "Name: Store_Longitude, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Store_Longitude\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\angelique\\anaconda3\\envs\\essai\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\angelique\\anaconda3\\envs\\essai\\lib\\site-packages (from geopy) (2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indore\n",
      "India\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from modules_amazon import Location\n",
    "\n",
    "#geolocator = Nominatim(user_agent=\"my_loc_app\")\n",
    "#def country(Latitude,Longitude):\n",
    "#    location = geolocator.reverse(Latitude+','+Longitude)\n",
    "#    address = location.raw[\"address\"]\n",
    "#    country = address.get(\"country\",\"\")\n",
    "#    return country\n",
    "latitude_0 = amazon_del.iloc[0,3]\n",
    "longitude_0 = amazon_del.iloc[0,4]\n",
    "loc = Location(latitude_0,longitude_0)\n",
    "print(loc.city())\n",
    "print(loc.country())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Order_Date**  \n",
    "No apparent missing values. I will switch to date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_del[\"Order_Date\"] = pd.to_datetime(amazon_del[\"Order_Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Order_Time**  \n",
    "No apparent missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angelique\\AppData\\Local\\Temp\\ipykernel_25320\\645566282.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  amazon_del[\"Order_Time\"] = pd.to_datetime(amazon_del[\"Order_Time\"]).dt.time\n"
     ]
    },
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: NaN , at position 174",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[181], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m amazon_del[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrder_Time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamazon_del\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOrder_Time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtime\n",
      "File \u001b[1;32mc:\\Users\\Angelique\\anaconda3\\envs\\Essai\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32mc:\\Users\\Angelique\\anaconda3\\envs\\Essai\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Angelique\\anaconda3\\envs\\Essai\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Angelique\\anaconda3\\envs\\Essai\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:666\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: NaN , at position 174"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Order_Time\"] = pd.to_datetime(amazon_del[\"Order_Time\"]).dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do have NaN starting at position 174. Why wasn't it considered as missing value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
      "173  wfjy432968933         28           4.8       18.530963        73.828972   \n",
      "174  opdl820466364         38           4.7       12.321214        76.621094   \n",
      "175  wbpn330130607         31           4.6       12.308500        76.665808   \n",
      "176  jtsd466670552         25           4.8       19.055831        72.833984   \n",
      "\n",
      "     Drop_Latitude  Drop_Longitude  Order_Date Order_Time Pickup_Time Weather  \\\n",
      "173      18.590963       73.888972  2022-03-03   19:00:00    19:05:00     Fog   \n",
      "174      12.361214       76.661094  2022-03-30   13:10:00    13:20:00   Windy   \n",
      "175      12.368500       76.725808  2022-03-19   17:55:00    18:05:00   Windy   \n",
      "176      19.115831       72.893984  2022-03-15   19:50:00    20:05:00  Cloudy   \n",
      "\n",
      "     Traffic      Vehicle            Area  Delivery_Time   Category  \n",
      "173  Medium      scooter           Urban              55      Books  \n",
      "174    High   motorcycle   Metropolitian             155  Cosmetics  \n",
      "175  Medium   motorcycle   Metropolitian             125   Skincare  \n",
      "176     Jam   motorcycle   Metropolitian             110    Jewelry  \n"
     ]
    }
   ],
   "source": [
    "print(amazon_del.iloc[172:176])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't have any NaN at this position or nearby. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11:30:00' '19:45:00' '08:30:00' '18:00:00' '13:30:00' '21:20:00'\n",
      " '19:15:00' '17:25:00' '20:55:00' '21:55:00' '14:55:00' '17:30:00'\n",
      " '09:20:00' '19:50:00' '20:25:00' '20:30:00' '20:40:00' '21:15:00'\n",
      " '20:20:00' '22:30:00' '08:15:00' '19:30:00' '12:25:00' '18:35:00'\n",
      " '20:35:00' '23:20:00' '23:35:00' '22:35:00' '23:25:00' '13:35:00'\n",
      " '21:35:00' '18:55:00' '14:15:00' '11:00:00' '09:45:00' '08:40:00'\n",
      " '23:00:00' '19:10:00' '10:55:00' '21:40:00' '19:00:00' '16:45:00'\n",
      " '15:10:00' '22:45:00' '22:10:00' '20:45:00' '22:50:00' '17:55:00'\n",
      " '09:25:00' '20:15:00' '22:25:00' '22:40:00' '23:50:00' '15:25:00'\n",
      " '10:20:00' '10:40:00' '15:55:00' '20:10:00' '12:10:00' '15:30:00'\n",
      " '10:35:00' '21:10:00' '20:50:00' '12:35:00' '21:00:00' '23:40:00'\n",
      " '18:15:00' '18:20:00' '11:45:00' '12:45:00' '23:30:00' '10:50:00'\n",
      " '21:25:00' '10:10:00' '17:50:00' '22:20:00' '12:40:00' '23:55:00'\n",
      " '10:25:00' '08:45:00' '23:45:00' '19:55:00' '22:15:00' '23:10:00'\n",
      " '09:15:00' '18:25:00' '18:45:00' '16:50:00' '00:00:00' '14:20:00'\n",
      " '10:15:00' '08:50:00' '09:00:00' '17:45:00' '16:35:00' '21:45:00'\n",
      " '19:40:00' '14:50:00' '18:10:00' '12:20:00' '12:50:00' '09:10:00'\n",
      " '12:30:00' '17:10:00' '17:20:00' '18:30:00' '13:10:00' '19:35:00'\n",
      " '09:50:00' '15:00:00' '20:00:00' '10:30:00' '09:40:00' '15:35:00'\n",
      " '16:55:00' '22:55:00' '16:00:00' '17:15:00' '21:30:00' '18:40:00'\n",
      " '11:10:00' '13:50:00' '10:00:00' '21:50:00' '11:50:00' '22:00:00'\n",
      " '08:25:00' '11:20:00' '11:55:00' '09:30:00' '08:20:00' '08:10:00'\n",
      " '11:40:00' '23:15:00' '19:20:00' '12:15:00' '11:35:00' '11:15:00'\n",
      " '17:35:00' '17:40:00' '14:40:00' '18:50:00' '11:25:00' '14:25:00'\n",
      " '12:00:00' '16:10:00' '19:25:00' '08:55:00' '13:40:00' '17:00:00'\n",
      " '09:35:00' '08:35:00' '16:15:00' '13:20:00' '15:50:00' '15:20:00'\n",
      " '16:20:00' '14:30:00' '15:45:00' '16:40:00' '13:00:00' '12:55:00'\n",
      " '10:45:00' '13:25:00' '09:55:00' '15:15:00' '13:15:00' '14:00:00'\n",
      " '15:40:00' '16:25:00' '14:10:00' '13:45:00' '13:55:00' '14:35:00' 'NaN '\n",
      " '16:30:00' '14:45:00']\n"
     ]
    }
   ],
   "source": [
    "print(amazon_del[\"Order_Time\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see a whitespace. That is the reason why it cannot be considered as missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, 2286 to 43490\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order_ID         91 non-null     object \n",
      " 1   Agent_Age        91 non-null     int64  \n",
      " 2   Agent_Rating     91 non-null     float64\n",
      " 3   Store_Latitude   91 non-null     float64\n",
      " 4   Store_Longitude  91 non-null     float64\n",
      " 5   Drop_Latitude    91 non-null     float64\n",
      " 6   Drop_Longitude   91 non-null     float64\n",
      " 7   Order_Date       91 non-null     object \n",
      " 8   Order_Time       91 non-null     object \n",
      " 9   Pickup_Time      91 non-null     object \n",
      " 10  Weather          0 non-null      object \n",
      " 11  Traffic          91 non-null     object \n",
      " 12  Vehicle          91 non-null     object \n",
      " 13  Area             91 non-null     object \n",
      " 14  Delivery_Time    91 non-null     int64  \n",
      " 15  Category         91 non-null     object \n",
      "dtypes: float64(5), int64(2), object(9)\n",
      "memory usage: 12.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Order_Time\"] = amazon_del[\"Order_Time\"].str.strip()\n",
    "missing_Order_Time = amazon_del[amazon_del[\"Order_Time\"] == \"NaN\"]\n",
    "print(missing_Order_Time.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, all the missing values Order_Time correlate with the absence of Weather values.  \n",
    "I won't remove them right away, I will tr< to understand why is that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pickup_Time**  \n",
    "No apparent missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11:45:00\n",
      "1    19:50:00\n",
      "2    08:45:00\n",
      "3    18:10:00\n",
      "4    13:45:00\n",
      "Name: Pickup_Time, dtype: object\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Pickup_Time\"] = pd.to_datetime(amazon_del[\"Pickup_Time\"], format=\"%H:%M:%S\")\n",
    "amazon_del[\"Pickup_Time\"] = amazon_del[\"Pickup_Time\"].dt.time\n",
    "print(amazon_del[\"Pickup_Time\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Weather**  \n",
    "Based on the info table there are 91 missing values. As observed above they all contain also missing Order_Time values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, 2286 to 43490\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order_ID         91 non-null     object \n",
      " 1   Agent_Age        91 non-null     int64  \n",
      " 2   Agent_Rating     91 non-null     float64\n",
      " 3   Store_Latitude   91 non-null     float64\n",
      " 4   Store_Longitude  91 non-null     float64\n",
      " 5   Drop_Latitude    91 non-null     float64\n",
      " 6   Drop_Longitude   91 non-null     float64\n",
      " 7   Order_Date       91 non-null     object \n",
      " 8   Order_Time       0 non-null      object \n",
      " 9   Pickup_Time      91 non-null     object \n",
      " 10  Weather          0 non-null      object \n",
      " 11  Traffic          91 non-null     object \n",
      " 12  Vehicle          91 non-null     object \n",
      " 13  Area             91 non-null     object \n",
      " 14  Delivery_Time    91 non-null     int64  \n",
      " 15  Category         91 non-null     object \n",
      "dtypes: float64(5), int64(2), object(9)\n",
      "memory usage: 12.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "missing_weather = amazon_del[amazon_del[\"Weather\"].isna()]\n",
    "non_missing_weather = amazon_del[~(amazon_del[\"Weather\"].isna())]\n",
    "print(missing_weather.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Agent_Age</th>\n",
       "      <th>Agent_Rating</th>\n",
       "      <th>Store_Latitude</th>\n",
       "      <th>Store_Longitude</th>\n",
       "      <th>Drop_Latitude</th>\n",
       "      <th>Drop_Longitude</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Order_Time</th>\n",
       "      <th>Pickup_Time</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Traffic</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Area</th>\n",
       "      <th>Delivery_Time</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>xige084493792</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-26.891191</td>\n",
       "      <td>75.802083</td>\n",
       "      <td>26.981191</td>\n",
       "      <td>75.892083</td>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>Urban</td>\n",
       "      <td>75</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>oilg311747812</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.750040</td>\n",
       "      <td>75.902847</td>\n",
       "      <td>22.810040</td>\n",
       "      <td>75.962847</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scooter</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>145</td>\n",
       "      <td>Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>pbox816153129</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.149569</td>\n",
       "      <td>72.772697</td>\n",
       "      <td>21.209569</td>\n",
       "      <td>72.832697</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>100</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>nzsa056960624</td>\n",
       "      <td>50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-12.970324</td>\n",
       "      <td>-77.645748</td>\n",
       "      <td>13.010324</td>\n",
       "      <td>77.685748</td>\n",
       "      <td>2022-03-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>van</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125</td>\n",
       "      <td>Cosmetics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>eids248121351</td>\n",
       "      <td>50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-17.451976</td>\n",
       "      <td>-78.385883</td>\n",
       "      <td>17.561976</td>\n",
       "      <td>78.495883</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>135</td>\n",
       "      <td>Jewelry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
       "2286  xige084493792         15           1.0      -26.891191        75.802083   \n",
       "2779  oilg311747812         15           1.0       22.750040        75.902847   \n",
       "2825  pbox816153129         15           1.0       21.149569        72.772697   \n",
       "3438  nzsa056960624         50           6.0      -12.970324       -77.645748   \n",
       "4514  eids248121351         50           6.0      -17.451976       -78.385883   \n",
       "\n",
       "      Drop_Latitude  Drop_Longitude  Order_Date Order_Time Pickup_Time  \\\n",
       "2286      26.981191       75.892083  2022-03-12        NaN    17:20:00   \n",
       "2779      22.810040       75.962847  2022-04-03        NaN    20:30:00   \n",
       "2825      21.209569       72.832697  2022-03-21        NaN    22:10:00   \n",
       "3438      13.010324       77.685748  2022-03-13        NaN    12:30:00   \n",
       "4514      17.561976       78.495883  2022-04-04        NaN    23:20:00   \n",
       "\n",
       "     Weather Traffic      Vehicle            Area  Delivery_Time   Category  \n",
       "2286     NaN    NaN   motorcycle           Urban              75       Home  \n",
       "2779     NaN    NaN      scooter   Metropolitian             145    Kitchen  \n",
       "2825     NaN    NaN      bicycle   Metropolitian             100   Clothing  \n",
       "3438     NaN    NaN           van          Urban             125  Cosmetics  \n",
       "4514     NaN    NaN      bicycle   Metropolitian             135    Jewelry  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['High ', 'Jam ', 'Low ', 'Medium ', 'NaN '], dtype=object)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Traffic\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, Traffic also have NaN values due again to a white space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NaN']\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Traffic\"] = amazon_del[\"Traffic\"].str.strip()\n",
    "missing_weather[\"Traffic\"] = missing_weather[\"Traffic\"].str.strip()\n",
    "print(missing_weather[\"Traffic\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angelique\\AppData\\Local\\Temp\\ipykernel_25320\\630223040.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  missing_weather[\"Traffic\"] = missing_weather[\"Traffic\"].replace(\"NaN\", np.nan)\n"
     ]
    }
   ],
   "source": [
    "missing_weather[\"Traffic\"] = missing_weather[\"Traffic\"].replace(\"NaN\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, 2286 to 43490\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order_ID         91 non-null     object \n",
      " 1   Agent_Age        91 non-null     int64  \n",
      " 2   Agent_Rating     91 non-null     float64\n",
      " 3   Store_Latitude   91 non-null     float64\n",
      " 4   Store_Longitude  91 non-null     float64\n",
      " 5   Drop_Latitude    91 non-null     float64\n",
      " 6   Drop_Longitude   91 non-null     float64\n",
      " 7   Order_Date       91 non-null     object \n",
      " 8   Order_Time       0 non-null      object \n",
      " 9   Pickup_Time      91 non-null     object \n",
      " 10  Weather          0 non-null      object \n",
      " 11  Traffic          0 non-null      float64\n",
      " 12  Vehicle          91 non-null     object \n",
      " 13  Area             91 non-null     object \n",
      " 14  Delivery_Time    91 non-null     int64  \n",
      " 15  Category         91 non-null     object \n",
      "dtypes: float64(6), int64(2), object(8)\n",
      "memory usage: 12.1+ KB\n"
     ]
    }
   ],
   "source": [
    "missing_weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now as well all the missing weather values also contain only Traffic null values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vehicle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['motorcycle ', 'scooter ', 'van', 'bicycle '], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Vehicle\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motorcycle' 'scooter' 'van' 'bicycle']\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Vehicle\"] = amazon_del[\"Vehicle\"].str.strip()\n",
    "print(amazon_del[\"Vehicle\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_vehicle = [\"bicycle\", \"scooter\", \"motorcycle\",\"van\"]\n",
    "amazon_del[\"Vehicle\"] = amazon_del[\"Vehicle\"].astype(\"category\")\n",
    "amazon_del[\"Vehicle\"] = amazon_del[\"Vehicle\"].cat.reorder_categories(new_categories=order_vehicle, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Urban ', 'Metropolitian ', 'Semi-Urban ', 'Other'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Area\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_del[\"Area\"] = amazon_del[\"Area\"].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_del[\"Area\"] = amazon_del[\"Area\"].replace(\"Metropolitian\",\"Metropolitan\")\n",
    "order_Area = [\"Other\",\"Semi-Urban\",\"Urban\",\"Metropolitan\"]\n",
    "amazon_del[\"Area\"] = amazon_del[\"Area\"].astype(\"category\")\n",
    "amazon_del[\"Area\"] = amazon_del[\"Area\"].cat.reorder_categories(new_categories=order_Area, ordered=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Delivery_Time**  \n",
    "No apparent missing values. That will be my dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    43685.000000\n",
      "mean       124.907588\n",
      "std         51.924227\n",
      "min         10.000000\n",
      "25%         90.000000\n",
      "50%        125.000000\n",
      "75%        160.000000\n",
      "max        270.000000\n",
      "Name: Delivery_Time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(amazon_del[\"Delivery_Time\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Category**  \n",
    "No apparent missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Clothing', 'Electronics', 'Sports', 'Cosmetics', 'Toys', 'Snacks',\n",
       "       'Shoes', 'Apparel', 'Jewelry', 'Outdoors', 'Grocery', 'Books',\n",
       "       'Kitchen', 'Home', 'Pet Supplies', 'Skincare'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a column for distance between the store point and the drop point**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a column for city and a column for country**  \n",
    "I have created a module allowing to determine the city and country names using the longitude and latitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Looking more closely at the peculiarity of the missing weather values**  \n",
    "Can I figure why I have three features missing (wheather, Order_Time and Traffic)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Essai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
