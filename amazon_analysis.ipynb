{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import math\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haversine in c:\\users\\angelique\\anaconda3\\envs\\essai\\lib\\site-packages (2.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43739 entries, 0 to 43738\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order_ID         43739 non-null  object \n",
      " 1   Agent_Age        43739 non-null  int64  \n",
      " 2   Agent_Rating     43685 non-null  float64\n",
      " 3   Store_Latitude   43739 non-null  float64\n",
      " 4   Store_Longitude  43739 non-null  float64\n",
      " 5   Drop_Latitude    43739 non-null  float64\n",
      " 6   Drop_Longitude   43739 non-null  float64\n",
      " 7   Order_Date       43739 non-null  object \n",
      " 8   Order_Time       43739 non-null  object \n",
      " 9   Pickup_Time      43739 non-null  object \n",
      " 10  Weather          43648 non-null  object \n",
      " 11  Traffic          43739 non-null  object \n",
      " 12  Vehicle          43739 non-null  object \n",
      " 13  Area             43739 non-null  object \n",
      " 14  Delivery_Time    43739 non-null  int64  \n",
      " 15  Category         43739 non-null  object \n",
      "dtypes: float64(5), int64(2), object(9)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "amazon_del = pd.read_csv(\"amazon_delivery.csv\")\n",
    "amazon_del.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Quick look column by column**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Order_ID**  \n",
    "Should be equivalent to PRIMARY KEY of a SQL table, only unique values. If so it can be removed when building a machine learning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates_order = amazon_del.duplicated(subset=[\"Order_ID\"])\n",
    "print(len(amazon_del[duplicates_order]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All IDs are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agent_Age**  \n",
    "On first sight everything seems ok. Type: integer and no missing values.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43739.000000\n",
       "mean        29.567137\n",
       "std          5.815155\n",
       "min         15.000000\n",
       "25%         25.000000\n",
       "50%         30.000000\n",
       "75%         35.000000\n",
       "max         50.000000\n",
       "Name: Agent_Age, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Agent_Age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Age = 0 or other abeerrant numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agent Rating**  \n",
    "Based on the info() table there are apparent missing values (54)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012345961270262237"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ratings = amazon_del[amazon_del[\"Agent_Rating\"].isna()]\n",
    "non_missing_ratings = amazon_del[~(amazon_del[\"Agent_Rating\"].isna())]\n",
    "len(missing_ratings)/len(amazon_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could potentially remove the values as they represent less than 1%. But I will see if other values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traffic\n",
       "Low        23\n",
       "Jam        15\n",
       "Medium     14\n",
       "High        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ratings[\"Traffic\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weather\n",
       "Windy         12\n",
       "Sunny         11\n",
       "Cloudy        11\n",
       "Stormy         8\n",
       "Sandstorms     7\n",
       "Fog            5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ratings[\"Weather\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can remove them. There are no obvious reason of these missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 43685 entries, 0 to 43738\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order_ID         43685 non-null  object \n",
      " 1   Agent_Age        43685 non-null  int64  \n",
      " 2   Agent_Rating     43685 non-null  float64\n",
      " 3   Store_Latitude   43685 non-null  float64\n",
      " 4   Store_Longitude  43685 non-null  float64\n",
      " 5   Drop_Latitude    43685 non-null  float64\n",
      " 6   Drop_Longitude   43685 non-null  float64\n",
      " 7   Order_Date       43685 non-null  object \n",
      " 8   Order_Time       43685 non-null  object \n",
      " 9   Pickup_Time      43685 non-null  object \n",
      " 10  Weather          43594 non-null  object \n",
      " 11  Traffic          43685 non-null  object \n",
      " 12  Vehicle          43685 non-null  object \n",
      " 13  Area             43685 non-null  object \n",
      " 14  Delivery_Time    43685 non-null  int64  \n",
      " 15  Category         43685 non-null  object \n",
      "dtypes: float64(5), int64(2), object(9)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "amazon_del = amazon_del.drop(missing_ratings.index, axis=0)\n",
    "amazon_del.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Store Latitude**  \n",
    "When the latitude is positive we are above the equator line. When the latitude is negative we are south to the equator line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43685.000000\n",
       "mean        17.214543\n",
       "std          7.750885\n",
       "min        -30.902872\n",
       "25%         12.933298\n",
       "50%         18.551440\n",
       "75%         22.732225\n",
       "max         30.914057\n",
       "Name: Store_Latitude, dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Store_Latitude\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Store Longitude**  \n",
    "No apparent missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43685.000000\n",
       "mean        70.668593\n",
       "std         21.459258\n",
       "min        -88.366217\n",
       "25%         73.170283\n",
       "50%         75.898497\n",
       "75%         78.045359\n",
       "max         88.433452\n",
       "Name: Store_Longitude, dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Store_Longitude\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\angelique\\anaconda3\\envs\\essai\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\angelique\\anaconda3\\envs\\essai\\lib\\site-packages (from geopy) (2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indore\n",
      "India\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from modules_amazon import Location\n",
    "\n",
    "latitude_0 = amazon_del.iloc[0,3]\n",
    "longitude_0 = amazon_del.iloc[0,4]\n",
    "loc = Location(latitude_0,longitude_0)\n",
    "print(loc.city())\n",
    "print(loc.country())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Order_Date**  \n",
    "No apparent missing values. I will switch to date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2022-03-19\n",
      "1    2022-03-25\n",
      "2    2022-03-19\n",
      "3    2022-04-05\n",
      "4    2022-03-26\n",
      "Name: Order_Date, dtype: object\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(amazon_del[\"Order_Date\"].head())\n",
    "amazon_del[\"Order_Date\"] = pd.to_datetime(amazon_del[\"Order_Date\"], format=\"%Y-%m-%d\")\n",
    "print(amazon_del[\"Order_Date\"].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Order_Time**  \n",
    "No apparent missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't have any NaN at this position or nearby. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11:30:00' '19:45:00' '08:30:00' '18:00:00' '13:30:00' '21:20:00'\n",
      " '19:15:00' '17:25:00' '20:55:00' '21:55:00' '14:55:00' '17:30:00'\n",
      " '09:20:00' '19:50:00' '20:25:00' '20:30:00' '20:40:00' '21:15:00'\n",
      " '20:20:00' '22:30:00' '08:15:00' '19:30:00' '12:25:00' '18:35:00'\n",
      " '20:35:00' '23:20:00' '23:35:00' '22:35:00' '23:25:00' '13:35:00'\n",
      " '21:35:00' '18:55:00' '14:15:00' '11:00:00' '09:45:00' '08:40:00'\n",
      " '23:00:00' '19:10:00' '10:55:00' '21:40:00' '19:00:00' '16:45:00'\n",
      " '15:10:00' '22:45:00' '22:10:00' '20:45:00' '22:50:00' '17:55:00'\n",
      " '09:25:00' '20:15:00' '22:25:00' '22:40:00' '23:50:00' '15:25:00'\n",
      " '10:20:00' '10:40:00' '15:55:00' '20:10:00' '12:10:00' '15:30:00'\n",
      " '10:35:00' '21:10:00' '20:50:00' '12:35:00' '21:00:00' '23:40:00'\n",
      " '18:15:00' '18:20:00' '11:45:00' '12:45:00' '23:30:00' '10:50:00'\n",
      " '21:25:00' '10:10:00' '17:50:00' '22:20:00' '12:40:00' '23:55:00'\n",
      " '10:25:00' '08:45:00' '23:45:00' '19:55:00' '22:15:00' '23:10:00'\n",
      " '09:15:00' '18:25:00' '18:45:00' '16:50:00' '00:00:00' '14:20:00'\n",
      " '10:15:00' '08:50:00' '09:00:00' '17:45:00' '16:35:00' '21:45:00'\n",
      " '19:40:00' '14:50:00' '18:10:00' '12:20:00' '12:50:00' '09:10:00'\n",
      " '12:30:00' '17:10:00' '17:20:00' '18:30:00' '13:10:00' '19:35:00'\n",
      " '09:50:00' '15:00:00' '20:00:00' '10:30:00' '09:40:00' '15:35:00'\n",
      " '16:55:00' '22:55:00' '16:00:00' '17:15:00' '21:30:00' '18:40:00'\n",
      " '11:10:00' '13:50:00' '10:00:00' '21:50:00' '11:50:00' '22:00:00'\n",
      " '08:25:00' '11:20:00' '11:55:00' '09:30:00' '08:20:00' '08:10:00'\n",
      " '11:40:00' '23:15:00' '19:20:00' '12:15:00' '11:35:00' '11:15:00'\n",
      " '17:35:00' '17:40:00' '14:40:00' '18:50:00' '11:25:00' '14:25:00'\n",
      " '12:00:00' '16:10:00' '19:25:00' '08:55:00' '13:40:00' '17:00:00'\n",
      " '09:35:00' '08:35:00' '16:15:00' '13:20:00' '15:50:00' '15:20:00'\n",
      " '16:20:00' '14:30:00' '15:45:00' '16:40:00' '13:00:00' '12:55:00'\n",
      " '10:45:00' '13:25:00' '09:55:00' '15:15:00' '13:15:00' '14:00:00'\n",
      " '15:40:00' '16:25:00' '14:10:00' '13:45:00' '13:55:00' '14:35:00' 'NaN '\n",
      " '16:30:00' '14:45:00']\n"
     ]
    }
   ],
   "source": [
    "print(amazon_del[\"Order_Time\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, I can see NaN written with a whitespace. That is the reason why it cannot be considered as missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, 2286 to 43490\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Order_ID         91 non-null     object        \n",
      " 1   Agent_Age        91 non-null     int64         \n",
      " 2   Agent_Rating     91 non-null     float64       \n",
      " 3   Store_Latitude   91 non-null     float64       \n",
      " 4   Store_Longitude  91 non-null     float64       \n",
      " 5   Drop_Latitude    91 non-null     float64       \n",
      " 6   Drop_Longitude   91 non-null     float64       \n",
      " 7   Order_Date       91 non-null     datetime64[ns]\n",
      " 8   Order_Time       91 non-null     object        \n",
      " 9   Pickup_Time      91 non-null     object        \n",
      " 10  Weather          0 non-null      object        \n",
      " 11  Traffic          91 non-null     object        \n",
      " 12  Vehicle          91 non-null     object        \n",
      " 13  Area             91 non-null     object        \n",
      " 14  Delivery_Time    91 non-null     int64         \n",
      " 15  Category         91 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(5), int64(2), object(8)\n",
      "memory usage: 12.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Order_Time\"] = amazon_del[\"Order_Time\"].str.strip()\n",
    "missing_Order_Time = amazon_del[amazon_del[\"Order_Time\"] == \"NaN\"]\n",
    "print(missing_Order_Time.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, all the missing values Order_Time correlate with the absence of Weather values.  \n",
    "I won't remove them right away, I will tr< to understand why is that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2024-12-03 11:30:00\n",
      "1   2024-12-03 19:45:00\n",
      "2   2024-12-03 08:30:00\n",
      "3   2024-12-03 18:00:00\n",
      "4   2024-12-03 13:30:00\n",
      "Name: Order_Time, dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angelique\\AppData\\Local\\Temp\\ipykernel_17496\\4021212013.py:1: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  amazon_del[\"Order_Time\"] = pd.to_datetime(amazon_del[\"Order_Time\"], infer_datetime_format=True, errors=\"coerce\")\n",
      "C:\\Users\\Angelique\\AppData\\Local\\Temp\\ipykernel_17496\\4021212013.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  amazon_del[\"Order_Time\"] = pd.to_datetime(amazon_del[\"Order_Time\"], infer_datetime_format=True, errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Order_Time\"] = pd.to_datetime(amazon_del[\"Order_Time\"], infer_datetime_format=True, errors=\"coerce\")\n",
    "print(amazon_del[\"Order_Time\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pickup_Time**  \n",
    "No apparent missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0    11:45:00\n",
      "1    19:50:00\n",
      "2    08:45:00\n",
      "3    18:10:00\n",
      "4    13:45:00\n",
      "Name: Pickup_Time, dtype: object\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Pickup_Time\"] = pd.to_datetime(amazon_del[\"Pickup_Time\"], format=\"%H:%M:%S\")\n",
    "amazon_del[\"Pickup_Time\"] = amazon_del[\"Pickup_Time\"].dt.time\n",
    "print(amazon_del[\"Pickup_Time\"].dtype)\n",
    "print(amazon_del[\"Pickup_Time\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Weather**  \n",
    "Based on the info table there are 91 missing values. As observed above they all contain also missing Order_Time values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, 2286 to 43490\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Order_ID         91 non-null     object        \n",
      " 1   Agent_Age        91 non-null     int64         \n",
      " 2   Agent_Rating     91 non-null     float64       \n",
      " 3   Store_Latitude   91 non-null     float64       \n",
      " 4   Store_Longitude  91 non-null     float64       \n",
      " 5   Drop_Latitude    91 non-null     float64       \n",
      " 6   Drop_Longitude   91 non-null     float64       \n",
      " 7   Order_Date       91 non-null     datetime64[ns]\n",
      " 8   Order_Time       0 non-null      datetime64[ns]\n",
      " 9   Pickup_Time      91 non-null     object        \n",
      " 10  Weather          0 non-null      object        \n",
      " 11  Traffic          91 non-null     object        \n",
      " 12  Vehicle          91 non-null     object        \n",
      " 13  Area             91 non-null     object        \n",
      " 14  Delivery_Time    91 non-null     int64         \n",
      " 15  Category         91 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(5), int64(2), object(7)\n",
      "memory usage: 12.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "missing_weather = amazon_del[amazon_del[\"Weather\"].isna()]\n",
    "non_missing_weather = amazon_del[~(amazon_del[\"Weather\"].isna())]\n",
    "print(missing_weather.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Agent_Age</th>\n",
       "      <th>Agent_Rating</th>\n",
       "      <th>Store_Latitude</th>\n",
       "      <th>Store_Longitude</th>\n",
       "      <th>Drop_Latitude</th>\n",
       "      <th>Drop_Longitude</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Order_Time</th>\n",
       "      <th>Pickup_Time</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Traffic</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Area</th>\n",
       "      <th>Delivery_Time</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>xige084493792</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-26.891191</td>\n",
       "      <td>75.802083</td>\n",
       "      <td>26.981191</td>\n",
       "      <td>75.892083</td>\n",
       "      <td>2022-03-12</td>\n",
       "      <td>NaT</td>\n",
       "      <td>17:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>Urban</td>\n",
       "      <td>75</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>oilg311747812</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.750040</td>\n",
       "      <td>75.902847</td>\n",
       "      <td>22.810040</td>\n",
       "      <td>75.962847</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaT</td>\n",
       "      <td>20:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scooter</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>145</td>\n",
       "      <td>Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>pbox816153129</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.149569</td>\n",
       "      <td>72.772697</td>\n",
       "      <td>21.209569</td>\n",
       "      <td>72.832697</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>22:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>100</td>\n",
       "      <td>Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>nzsa056960624</td>\n",
       "      <td>50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-12.970324</td>\n",
       "      <td>-77.645748</td>\n",
       "      <td>13.010324</td>\n",
       "      <td>77.685748</td>\n",
       "      <td>2022-03-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>van</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125</td>\n",
       "      <td>Cosmetics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>eids248121351</td>\n",
       "      <td>50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-17.451976</td>\n",
       "      <td>-78.385883</td>\n",
       "      <td>17.561976</td>\n",
       "      <td>78.495883</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>23:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>Metropolitian</td>\n",
       "      <td>135</td>\n",
       "      <td>Jewelry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
       "2286  xige084493792         15           1.0      -26.891191        75.802083   \n",
       "2779  oilg311747812         15           1.0       22.750040        75.902847   \n",
       "2825  pbox816153129         15           1.0       21.149569        72.772697   \n",
       "3438  nzsa056960624         50           6.0      -12.970324       -77.645748   \n",
       "4514  eids248121351         50           6.0      -17.451976       -78.385883   \n",
       "\n",
       "      Drop_Latitude  Drop_Longitude Order_Date Order_Time Pickup_Time Weather  \\\n",
       "2286      26.981191       75.892083 2022-03-12        NaT    17:20:00     NaN   \n",
       "2779      22.810040       75.962847 2022-04-03        NaT    20:30:00     NaN   \n",
       "2825      21.209569       72.832697 2022-03-21        NaT    22:10:00     NaN   \n",
       "3438      13.010324       77.685748 2022-03-13        NaT    12:30:00     NaN   \n",
       "4514      17.561976       78.495883 2022-04-04        NaT    23:20:00     NaN   \n",
       "\n",
       "     Traffic      Vehicle            Area  Delivery_Time   Category  \n",
       "2286    NaN   motorcycle           Urban              75       Home  \n",
       "2779    NaN      scooter   Metropolitian             145    Kitchen  \n",
       "2825    NaN      bicycle   Metropolitian             100   Clothing  \n",
       "3438    NaN           van          Urban             125  Cosmetics  \n",
       "4514    NaN      bicycle   Metropolitian             135    Jewelry  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['High ', 'Jam ', 'Low ', 'Medium ', 'NaN '], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Traffic\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, Traffic also have NaN values due again to a white space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NaN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angelique\\AppData\\Local\\Temp\\ipykernel_17496\\3635599610.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_weather[\"Traffic\"] = missing_weather[\"Traffic\"].str.strip()\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Traffic\"] = amazon_del[\"Traffic\"].str.strip()\n",
    "missing_weather[\"Traffic\"] = missing_weather[\"Traffic\"].str.strip()\n",
    "print(missing_weather[\"Traffic\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angelique\\AppData\\Local\\Temp\\ipykernel_17496\\630223040.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  missing_weather[\"Traffic\"] = missing_weather[\"Traffic\"].replace(\"NaN\", np.nan)\n",
      "C:\\Users\\Angelique\\AppData\\Local\\Temp\\ipykernel_17496\\630223040.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_weather[\"Traffic\"] = missing_weather[\"Traffic\"].replace(\"NaN\", np.nan)\n"
     ]
    }
   ],
   "source": [
    "missing_weather[\"Traffic\"] = missing_weather[\"Traffic\"].replace(\"NaN\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, 2286 to 43490\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Order_ID         91 non-null     object        \n",
      " 1   Agent_Age        91 non-null     int64         \n",
      " 2   Agent_Rating     91 non-null     float64       \n",
      " 3   Store_Latitude   91 non-null     float64       \n",
      " 4   Store_Longitude  91 non-null     float64       \n",
      " 5   Drop_Latitude    91 non-null     float64       \n",
      " 6   Drop_Longitude   91 non-null     float64       \n",
      " 7   Order_Date       91 non-null     datetime64[ns]\n",
      " 8   Order_Time       0 non-null      datetime64[ns]\n",
      " 9   Pickup_Time      91 non-null     object        \n",
      " 10  Weather          0 non-null      object        \n",
      " 11  Traffic          0 non-null      float64       \n",
      " 12  Vehicle          91 non-null     object        \n",
      " 13  Area             91 non-null     object        \n",
      " 14  Delivery_Time    91 non-null     int64         \n",
      " 15  Category         91 non-null     object        \n",
      "dtypes: datetime64[ns](2), float64(6), int64(2), object(6)\n",
      "memory usage: 12.1+ KB\n"
     ]
    }
   ],
   "source": [
    "missing_weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now as well all the missing weather values also contain only Traffic null values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vehicle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['motorcycle ', 'scooter ', 'van', 'bicycle '], dtype=object)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Vehicle\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motorcycle' 'scooter' 'van' 'bicycle']\n"
     ]
    }
   ],
   "source": [
    "amazon_del[\"Vehicle\"] = amazon_del[\"Vehicle\"].str.strip()\n",
    "print(amazon_del[\"Vehicle\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_vehicle = [\"bicycle\", \"scooter\", \"motorcycle\",\"van\"]\n",
    "amazon_del[\"Vehicle\"] = amazon_del[\"Vehicle\"].astype(\"category\")\n",
    "amazon_del[\"Vehicle\"] = amazon_del[\"Vehicle\"].cat.reorder_categories(new_categories=order_vehicle, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Urban ', 'Metropolitian ', 'Semi-Urban ', 'Other'], dtype=object)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Area\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_del[\"Area\"] = amazon_del[\"Area\"].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_del[\"Area\"] = amazon_del[\"Area\"].replace(\"Metropolitian\",\"Metropolitan\")\n",
    "order_Area = [\"Other\",\"Semi-Urban\",\"Urban\",\"Metropolitan\"]\n",
    "amazon_del[\"Area\"] = amazon_del[\"Area\"].astype(\"category\")\n",
    "amazon_del[\"Area\"] = amazon_del[\"Area\"].cat.reorder_categories(new_categories=order_Area, ordered=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Delivery_Time**  \n",
    "No apparent missing values. That will be my dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    43685.000000\n",
      "mean       124.907588\n",
      "std         51.924227\n",
      "min         10.000000\n",
      "25%         90.000000\n",
      "50%        125.000000\n",
      "75%        160.000000\n",
      "max        270.000000\n",
      "Name: Delivery_Time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(amazon_del[\"Delivery_Time\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Category**  \n",
    "No apparent missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Clothing', 'Electronics', 'Sports', 'Cosmetics', 'Toys', 'Snacks',\n",
       "       'Shoes', 'Apparel', 'Jewelry', 'Outdoors', 'Grocery', 'Books',\n",
       "       'Kitchen', 'Home', 'Pet Supplies', 'Skincare'], dtype=object)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_del[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a column for distance between the store point and the drop point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    43685.000000\n",
      "mean        38.077532\n",
      "std        532.442985\n",
      "min          1.465069\n",
      "25%          4.663439\n",
      "50%          9.220463\n",
      "75%         13.682398\n",
      "max      19692.701807\n",
      "Name: Distance_Store_Drop_km, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import haversine as hs\n",
    "from haversine import Unit\n",
    "\n",
    "distance = []\n",
    "for loc1,loc2 in zip(zip(amazon_del[\"Store_Latitude\"],amazon_del[\"Store_Longitude\"]),\\\n",
    "                     zip(amazon_del[\"Drop_Latitude\"],amazon_del[\"Drop_Longitude\"])):\n",
    "    dist = hs.haversine(loc1,loc2, unit=Unit.KILOMETERS)\n",
    "    distance.append(dist)\n",
    "    \n",
    "amazon_del[\"Distance_Store_Drop_km\"] = distance\n",
    "print(amazon_del[\"Distance_Store_Drop_km\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max distance is aberrantly high. I will see how many of these I have and if I can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 183 entries, 90 to 43343\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Order_ID                183 non-null    object        \n",
      " 1   Agent_Age               183 non-null    int64         \n",
      " 2   Agent_Rating            183 non-null    float64       \n",
      " 3   Store_Latitude          183 non-null    float64       \n",
      " 4   Store_Longitude         183 non-null    float64       \n",
      " 5   Drop_Latitude           183 non-null    float64       \n",
      " 6   Drop_Longitude          183 non-null    float64       \n",
      " 7   Order_Date              183 non-null    datetime64[ns]\n",
      " 8   Order_Time              151 non-null    datetime64[ns]\n",
      " 9   Pickup_Time             183 non-null    object        \n",
      " 10  Weather                 151 non-null    object        \n",
      " 11  Traffic                 183 non-null    object        \n",
      " 12  Vehicle                 183 non-null    category      \n",
      " 13  Area                    183 non-null    category      \n",
      " 14  Delivery_Time           183 non-null    int64         \n",
      " 15  Category                183 non-null    object        \n",
      " 16  Distance_Store_Drop_km  183 non-null    float64       \n",
      "dtypes: category(2), datetime64[ns](2), float64(6), int64(2), object(5)\n",
      "memory usage: 23.6+ KB\n",
      "None\n",
      "27.21083647393771\n"
     ]
    }
   ],
   "source": [
    "iqr_dist = np.quantile(amazon_del[\"Distance_Store_Drop_km\"],0.75) - np.quantile(amazon_del[\"Distance_Store_Drop_km\"],0.25)\n",
    "sup_outlier_dist = np.quantile(amazon_del[\"Distance_Store_Drop_km\"], 0.75) + 1.5*iqr_dist\n",
    "dist_outliers_sup = amazon_del[amazon_del[\"Distance_Store_Drop_km\"] > sup_outlier_dist]\n",
    "\n",
    "print(dist_outliers_sup.info())\n",
    "print(sup_outlier_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amazon_del[amazon_del[\"Distance_Store_Drop_km\"] >= 19000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Order_ID  Agent_Age  Agent_Rating  Store_Latitude  \\\n",
      "9148   jysr585437673         50           6.0      -23.374989   \n",
      "13106  giiq483839538         50           6.0      -23.416792   \n",
      "21446  jthh363774386         15           1.0      -23.351058   \n",
      "32179  qkrp333211010         50           6.0      -22.533662   \n",
      "\n",
      "       Store_Longitude  Drop_Latitude  Drop_Longitude Order_Date Order_Time  \\\n",
      "9148        -85.335486      23.444989       85.405486 2022-03-20        NaT   \n",
      "13106       -85.316842      23.466792       85.366842 2022-03-13        NaT   \n",
      "21446       -85.325731      23.421058       85.395731 2022-03-27        NaT   \n",
      "32179       -88.366217      22.663662       88.496217 2022-02-18        NaT   \n",
      "\n",
      "      Pickup_Time Weather Traffic     Vehicle          Area  Delivery_Time  \\\n",
      "9148     17:55:00     NaN     NaN     bicycle  Metropolitan            160   \n",
      "13106    20:40:00     NaN     NaN  motorcycle  Metropolitan            140   \n",
      "21446    21:35:00     NaN     NaN         van  Metropolitan            220   \n",
      "32179    21:50:00     NaN     NaN     scooter  Metropolitan            140   \n",
      "\n",
      "       Category  Distance_Store_Drop_km  \n",
      "9148       Home            19070.434451  \n",
      "13106  Outdoors            19064.836450  \n",
      "21446    Snacks            19068.273300  \n",
      "32179   Apparel            19692.701807  \n"
     ]
    }
   ],
   "source": [
    "print(amazon_del[amazon_del[\"Distance_Store_Drop_km\"] >= 19000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah ah! The problem is the Drop_Latitude and Drop_Longitude. The coordinates are at the opposite of the Store coordinates. I can impute them. I will know better when I will know the countries involved in this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a column for city and a column for country**  \n",
    "I have created a module allowing to determine the city and country names using the longitude and latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "count      183.000000\n",
      "mean      6775.900325\n",
      "std       4711.467596\n",
      "min       2216.068855\n",
      "25%       4423.349282\n",
      "50%       5173.323369\n",
      "75%       6748.175550\n",
      "max      19692.701807\n",
      "Name: Distance_Store_Drop_km, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from modules_amazon import Location\n",
    "\n",
    "aberr_dist = amazon_del[amazon_del[\"Distance_Store_Drop_km\"] >= 100 ]\n",
    "print(len(aberr_dist))\n",
    "print(aberr_dist[\"Distance_Store_Drop_km\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The superior outliers have all >100 km distance. They have actually a median of 5173km distance (the median of our sample is 9km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    183.000000\n",
      "mean     -21.487587\n",
      "std        6.184380\n",
      "min      -30.902872\n",
      "25%      -26.472849\n",
      "50%      -22.538999\n",
      "75%      -15.569600\n",
      "max       -9.959778\n",
      "Name: Store_Latitude, dtype: float64\n",
      "count    183.000000\n",
      "mean      55.696719\n",
      "std       56.227809\n",
      "min      -88.366217\n",
      "25%       73.950889\n",
      "50%       76.307589\n",
      "75%       80.318244\n",
      "max       88.433452\n",
      "Name: Store_Longitude, dtype: float64\n",
      "count    43502.000000\n",
      "mean        17.377351\n",
      "std          7.337660\n",
      "min          0.000000\n",
      "25%         12.934179\n",
      "50%         18.554382\n",
      "75%         22.732225\n",
      "max         30.914057\n",
      "Name: Store_Latitude, dtype: float64\n",
      "count    43502.000000\n",
      "mean        70.731575\n",
      "std         21.172214\n",
      "min          0.000000\n",
      "25%         73.170283\n",
      "50%         75.898497\n",
      "75%         78.044095\n",
      "max         88.433452\n",
      "Name: Store_Longitude, dtype: float64\n",
      "India\n"
     ]
    }
   ],
   "source": [
    "print(dist_outliers_sup[\"Store_Latitude\"].describe())\n",
    "print(dist_outliers_sup[\"Store_Longitude\"].describe())\n",
    "\n",
    "no_outliers = amazon_del[~(amazon_del[\"Distance_Store_Drop_km\"] >= sup_outlier_dist)]\n",
    "print(no_outliers[\"Store_Latitude\"].describe())\n",
    "print(no_outliers[\"Store_Longitude\"].describe())\n",
    "\n",
    "loc = Location(18.5,75.9)\n",
    "print(loc.country())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data outside the outliers is based (or mainly) in India. I will therefore switch to the positive coordinates and recalculate the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_del[\"abs_Store_Latitude\"] = abs(amazon_del[\"Store_Latitude\"])\n",
    "amazon_del[\"abs_Store_Longitude\"] = abs(amazon_del[\"Store_Longitude\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    43685.000000\n",
      "mean         9.732511\n",
      "std          5.604092\n",
      "min          1.465069\n",
      "25%          4.663418\n",
      "50%          9.220160\n",
      "75%         13.681435\n",
      "max         20.969518\n",
      "Name: Distance_Store_Drop_km, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "distance = []\n",
    "for loc1,loc2 in zip(zip(amazon_del[\"abs_Store_Latitude\"],amazon_del[\"abs_Store_Longitude\"]),\\\n",
    "                     zip(amazon_del[\"Drop_Latitude\"],amazon_del[\"Drop_Longitude\"])):\n",
    "    dist = hs.haversine(loc1,loc2, unit=Unit.KILOMETERS)\n",
    "    distance.append(dist)\n",
    "    \n",
    "amazon_del[\"Distance_Store_Drop_km\"] = distance\n",
    "\n",
    "print(amazon_del[\"Distance_Store_Drop_km\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating a column city**  \n",
    "Because the median of the Store coordinates is located in India and that the median distance is 9km, I can confidently conclude that at least most of the data is located in India.  \n",
    "Hence, I will only make a \"city\" column to see if there are discrepancies between cities.  \n",
    "However, the size of the dataset is too large. I will make a sample of 400 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_sample400 = amazon_del.sample(n=400, replace=False, random_state=1984)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "City_Stores = []\n",
    "for lat,long in zip(amazon_sample400[\"abs_Store_Latitude\"],amazon_sample400[\"abs_Store_Longitude\"]) :\n",
    "    loc = Location(lat,long)\n",
    "    City_Stores.append(loc.city())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'Mysuru' 'Mumbai Suburban' 'Coimbatore' 'Indore' 'Kolkata' 'Jaipur'\n",
      " 'Ranchi' 'Prayagraj' 'Pune City' 'Bhopal' 'Dehradun' 'Kanpur' 'Surat'\n",
      " 'Agra' 'Hyderabad' 'Chhatrapati Sambhaji Nagar' 'Bengaluru' 'Mumbai City'\n",
      " 'Ernakulam' 'Chennai' 'Vadodara' 'Ludhiana'\n",
      " 'Jaipur Municipal Corporation' 'Thane']\n"
     ]
    }
   ],
   "source": [
    "amazon_sample400[\"City\"] = City_Stores\n",
    "print(amazon_sample400[\"City\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 400 entries, 4628 to 16065\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Order_ID                400 non-null    object        \n",
      " 1   Agent_Age               400 non-null    int64         \n",
      " 2   Agent_Rating            400 non-null    float64       \n",
      " 3   Store_Latitude          400 non-null    float64       \n",
      " 4   Store_Longitude         400 non-null    float64       \n",
      " 5   Drop_Latitude           400 non-null    float64       \n",
      " 6   Drop_Longitude          400 non-null    float64       \n",
      " 7   Order_Date              400 non-null    datetime64[ns]\n",
      " 8   Order_Time              399 non-null    datetime64[ns]\n",
      " 9   Pickup_Time             400 non-null    object        \n",
      " 10  Weather                 399 non-null    object        \n",
      " 11  Traffic                 400 non-null    object        \n",
      " 12  Vehicle                 400 non-null    category      \n",
      " 13  Area                    400 non-null    category      \n",
      " 14  Delivery_Time           400 non-null    int64         \n",
      " 15  Category                400 non-null    object        \n",
      " 16  Distance_Store_Drop_km  400 non-null    float64       \n",
      " 17  abs_Store_Latitude      400 non-null    float64       \n",
      " 18  abs_Store_Longitude     400 non-null    float64       \n",
      " 19  City                    400 non-null    object        \n",
      "dtypes: category(2), datetime64[ns](2), float64(8), int64(2), object(6)\n",
      "memory usage: 60.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(amazon_sample400.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample I have only 1 unknown wheather value, meaning that I also have 1 order and 1 traffic missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EDA with the amazon_sample400 new dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first remove the missing weather row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 399 entries, 4628 to 16065\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Order_ID                399 non-null    object        \n",
      " 1   Agent_Age               399 non-null    int64         \n",
      " 2   Agent_Rating            399 non-null    float64       \n",
      " 3   Store_Latitude          399 non-null    float64       \n",
      " 4   Store_Longitude         399 non-null    float64       \n",
      " 5   Drop_Latitude           399 non-null    float64       \n",
      " 6   Drop_Longitude          399 non-null    float64       \n",
      " 7   Order_Date              399 non-null    datetime64[ns]\n",
      " 8   Order_Time              399 non-null    datetime64[ns]\n",
      " 9   Pickup_Time             399 non-null    object        \n",
      " 10  Weather                 399 non-null    object        \n",
      " 11  Traffic                 399 non-null    object        \n",
      " 12  Vehicle                 399 non-null    category      \n",
      " 13  Area                    399 non-null    category      \n",
      " 14  Delivery_Time           399 non-null    int64         \n",
      " 15  Category                399 non-null    object        \n",
      " 16  Distance_Store_Drop_km  399 non-null    float64       \n",
      " 17  abs_Store_Latitude      399 non-null    float64       \n",
      " 18  abs_Store_Longitude     399 non-null    float64       \n",
      " 19  City                    399 non-null    object        \n",
      "dtypes: category(2), datetime64[ns](2), float64(8), int64(2), object(6)\n",
      "memory usage: 60.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "amazon_sample400 = amazon_sample400.dropna(subset=[\"Weather\"])\n",
    "print(amazon_sample400.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Is Delivery time the difference between order time and pickup time?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Essai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
